{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_images_and_labels_from_csv(csv_path, images_dir, image_size=(32, 32), num_classes=43):\n",
    "    images = []\n",
    "    labels = []\n",
    "    data = pd.read_csv(csv_path)\n",
    "    for idx, row in data.iterrows():\n",
    "        image_path = os.path.join(images_dir, row['Path'].replace('/', os.sep))\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, image_size)\n",
    "            images.append(image)\n",
    "            labels.append(int(row['ClassId']))\n",
    "        else:\n",
    "            print(f\"Failed to load image at path: {image_path}\")\n",
    "    images = np.array(images).astype('float32') / 255.0\n",
    "    labels = to_categorical(np.array(labels), num_classes)\n",
    "    return images, labels\n",
    "train_dir = r'C:\\Users\\Abdullah\\Desktop\\Derin_Ogrenme\\GTSRB'\n",
    "train_csv = r'C:\\Users\\Abdullah\\Desktop\\Derin_Ogrenme\\GTSRB\\Train.csv'\n",
    "valid_dir = r'C:\\Users\\Abdullah\\Desktop\\Derin_Ogrenme\\GTSRB'\n",
    "valid_csv = r'C:\\Users\\Abdullah\\Desktop\\Derin_Ogrenme\\GTSRB\\Meta.csv'\n",
    "test_dir = r'C:\\Users\\Abdullah\\Desktop\\Derin_Ogrenme\\GTSRB'\n",
    "test_csv = r'C:\\Users\\Abdullah\\Desktop\\Derin_Ogrenme\\GTSRB\\Test.csv'\n",
    "\n",
    "X_train, y_train = load_images_and_labels_from_csv(train_csv, train_dir)\n",
    "X_valid, y_valid = load_images_and_labels_from_csv(valid_csv, valid_dir)\n",
    "X_test, y_test = load_images_and_labels_from_csv(test_csv, test_dir)\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation data shape:\", X_valid.shape, y_valid.shape)\n",
    "print(\"Test data shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Özelleştirilmiş CNN modelini oluşturalım\n",
    "def create_custom_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Modeli oluştur\n",
    "input_shape = (32, 32, 3)  # Örnek olarak 32x32 boyutunda ve 3 kanallı bir giriş\n",
    "num_classes = 10  # Örnek olarak 10 sınıf\n",
    "custom_model = create_custom_model(input_shape, num_classes)\n",
    "\n",
    "# Modeli eğitelim\n",
    "history_custom = custom_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")\n",
    "\n",
    "# Model performansını değerlendirelim\n",
    "y_pred = custom_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Performans metrikleri\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes))\n",
    "report = classification_report(y_true, y_pred_classes, output_dict=True)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Performans özet\n",
    "test_accuracy = report['accuracy']\n",
    "precision = report['macro avg']['precision']\n",
    "recall = report['macro avg']['recall']\n",
    "f1_score = report['macro avg']['f1-score']\n",
    "print(f\"Accuracy: {test_accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Transfer öğrenme modelini oluşturalım (MobileNetV2)\n",
    "input_shape = (128, 128, 3)  # Örnek olarak 128x128 boyutunda ve 3 kanallı bir giriş\n",
    "num_classes = 10  # Örnek olarak 10 sınıf\n",
    "base_model_mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "transfer_mobilenet = Sequential([\n",
    "    base_model_mobilenet,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "transfer_mobilenet.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Modeli eğitelim (MobileNetV2)\n",
    "history_mobilenet = transfer_mobilenet.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")\n",
    "\n",
    "# Model performansını değerlendirme (MobileNetV2)\n",
    "y_pred_mobilenet = transfer_mobilenet.predict(X_test)\n",
    "y_pred_classes_mobilenet = np.argmax(y_pred_mobilenet, axis=1)\n",
    "y_true_mobilenet = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Performans metrikleri\n",
    "print(\"Classification Report (MobileNetV2):\")\n",
    "print(classification_report(y_true_mobilenet, y_pred_classes_mobilenet))\n",
    "report_mobilenet = classification_report(y_true_mobilenet, y_pred_classes_mobilenet, output_dict=True)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_mobilenet = confusion_matrix(y_true_mobilenet, y_pred_classes_mobilenet)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_mobilenet, annot=True, fmt=\"d\", cmap='Blues')\n",
    "plt.title('Confusion Matrix (MobileNetV2)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Performans özet\n",
    "test_accuracy_mobilenet = report_mobilenet['accuracy']\n",
    "precision_mobilenet = report_mobilenet['macro avg']['precision']\n",
    "recall_mobilenet = report_mobilenet['macro avg']['recall']\n",
    "f1_score_mobilenet = report_mobilenet['macro avg']['f1-score']\n",
    "print(f\"Accuracy: {test_accuracy_mobilenet:.4f}, Precision: {precision_mobilenet:.4f}, Recall: {recall_mobilenet:.4f}, F1-Score: {f1_score_mobilenet:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
